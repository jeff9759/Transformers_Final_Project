{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# Business GPT Demonstration Notebook\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Notebook Purpose\n",
    "\"\"\"\n",
    "This notebook demonstrates how advanced prompt engineering techniques can \n",
    "facilitate seamless data-sharing and collaboration across departments using \n",
    "'Business GPT.' We showcase examples of zero-shot, few-shot, chain-of-thought (CoT), \n",
    "prompt chaining, and retrieval-augmented generation (RAG) in business contexts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 1. Importing Required Libraries\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "from transformers import pipeline, AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e209dbaf3f24166ac6bbcc63c56b66d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/1.15k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0169b43cde134646b8eb8c48a111a4a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.63G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e98c256bd814de4bf71e2a64c64b5a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e8a2cfbf060d4a1ea0cca5f164749a50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bec6e44f6ca54583a32070c9c5e2d8c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2465107dead047598f4d5f5189f2787e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Hardware accelerator e.g. GPU is available in the environment, but no `device` argument is passed to the `Pipeline` object. Model will be on CPU.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Zero-Shot Prompting Example ###\n",
      "Query: Analyze sentiment: 'Our sales performance exceeded expectations this quarter.'\n",
      "Classification Response: {'sequence': \"Analyze sentiment: 'Our sales performance exceeded expectations this quarter.'\", 'labels': ['Positive', 'Neutral', 'Negative'], 'scores': [0.9140205979347229, 0.059068601578474045, 0.026910770684480667]}\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 2. Zero-Shot Prompting Example\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Load a pre-trained zero-shot classification model\n",
    "classifier = pipeline(\"zero-shot-classification\", model=\"facebook/bart-large-mnli\")\n",
    "\n",
    "# Example business query\n",
    "query = \"Analyze sentiment: 'Our sales performance exceeded expectations this quarter.'\"\n",
    "labels = [\"Positive\", \"Negative\", \"Neutral\"]\n",
    "\n",
    "response = classifier(query, candidate_labels=labels)\n",
    "\n",
    "# Output the result\n",
    "print(\"### Zero-Shot Prompting Example ###\")\n",
    "print(f\"Query: {query}\")\n",
    "print(\"Classification Response:\", response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Few-Shot Prompting Example ###\n",
      "Prompt:\n",
      "\n",
      "Review: \"The new product is exceptional!\" // Positive\n",
      "Review: \"The customer service experience was disappointing.\" // Negative\n",
      "Review: \"Delivery was fast and on time.\" // Positive\n",
      "Review: \"The product failed to meet quality standards.\" //\n",
      "Model Response: Negative\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 3. Few-Shot Prompting Example\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Few-shot example: Manually constructing the context\n",
    "few_shot_prompt = \"\"\"\n",
    "Review: \"The new product is exceptional!\" // Positive\n",
    "Review: \"The customer service experience was disappointing.\" // Negative\n",
    "Review: \"Delivery was fast and on time.\" // Positive\n",
    "Review: \"The product failed to meet quality standards.\" //\"\"\"\n",
    "\n",
    "print(\"\\n### Few-Shot Prompting Example ###\")\n",
    "print(f\"Prompt:\\n{few_shot_prompt}\")\n",
    "print(\"Model Response: Negative\")  # Simulated response for now\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Chain-of-Thought Prompting Example ###\n",
      "Prompt:\n",
      "\n",
      "A company started with $1,000,000 in revenue. They allocated $300,000 to operations, \n",
      "$200,000 to marketing, and $150,000 to research and development. Later, they generated \n",
      "an additional $500,000 in revenue but spent $100,000 on a new product launch. \n",
      "How much revenue remains? Let’s think step by step.\n",
      "\n",
      "Step-by-Step Response:\n",
      "\n",
      "1. The company started with $1,000,000 in revenue.\n",
      "2. They spent $300,000 on operations, $200,000 on marketing, and $150,000 on R&D, leaving $350,000.\n",
      "3. They generated an additional $500,000, increasing total revenue to $850,000.\n",
      "4. They spent $100,000 on a product launch, leaving $750,000 in revenue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 4. Chain-of-Thought Prompting Example\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Chain-of-thought example in business context\n",
    "cot_prompt = \"\"\"\n",
    "A company started with $1,000,000 in revenue. They allocated $300,000 to operations, \n",
    "$200,000 to marketing, and $150,000 to research and development. Later, they generated \n",
    "an additional $500,000 in revenue but spent $100,000 on a new product launch. \n",
    "How much revenue remains? Let’s think step by step.\n",
    "\"\"\"\n",
    "\n",
    "cot_output = \"\"\"\n",
    "1. The company started with $1,000,000 in revenue.\n",
    "2. They spent $300,000 on operations, $200,000 on marketing, and $150,000 on R&D, leaving $350,000.\n",
    "3. They generated an additional $500,000, increasing total revenue to $850,000.\n",
    "4. They spent $100,000 on a product launch, leaving $750,000 in revenue.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n### Chain-of-Thought Prompting Example ###\")\n",
    "print(f\"Prompt:\\n{cot_prompt}\")\n",
    "print(f\"Step-by-Step Response:\\n{cot_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Retrieval-Augmented Generation Example ###\n",
      "Query: What was the Q3 2024 revenue and profit?\n",
      "Response:\n",
      "Retrieved Information: ['Q3 2024 revenue: $10M; profit: $2.5M']\n",
      "Answer: The Q3 2024 revenue was $10M, with a profit of $2.5M.\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 5. Retrieval-Augmented Generation (RAG) Example\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Simulated retrieval of relevant documents\n",
    "documents = [\n",
    "    \"Q3 2024 revenue: $10M; profit: $2.5M\",\n",
    "    \"Marketing ROI: 150%\",\n",
    "    \"Sales pipeline: 300 leads\"\n",
    "]\n",
    "\n",
    "query = \"What was the Q3 2024 revenue and profit?\"\n",
    "retrieved_info = [doc for doc in documents if \"Q3 2024\" in doc]\n",
    "\n",
    "# Generate a response based on retrieved info\n",
    "rag_output = f\"Retrieved Information: {retrieved_info}\\nAnswer: The Q3 2024 revenue was $10M, with a profit of $2.5M.\"\n",
    "\n",
    "print(\"\\n### Retrieval-Augmented Generation Example ###\")\n",
    "print(f\"Query: {query}\")\n",
    "print(f\"Response:\\n{rag_output}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca42d53aa94d4b719c05b12303eb67d9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4e2a6bdad4443f88aceb18448cbe3b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b16f4096b3f41b88c83e385cf4f7c55",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef56c8eb35634ae5a4c9bd83cdc8fe1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "28a20a0f4cec4b7aa4693922e8effc05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ceee19664d5b4fa7a98318bd71147330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cd52e203687048c490ff2a9631ea4f50",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Interactive Prompting Playground ###\n"
     ]
    }
   ],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 6. Interactive Prompting Playground\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "# Load a GPT-2 model for generating responses\n",
    "model_name = \"gpt2\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "print(\"\\n### Interactive Prompting Playground ###\")\n",
    "user_prompt = input(\"Enter your business query: \")\n",
    "input_ids = tokenizer.encode(user_prompt, return_tensors=\"pt\")\n",
    "output = model.generate(input_ids, max_length=50)\n",
    "\n",
    "print(\"Model Response:\", tokenizer.decode(output[0], skip_special_tokens=True))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "# 7. Summary and Next Steps\n",
    "#%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%\n",
    "\n",
    "\"\"\"\n",
    "This notebook demonstrated the application of advanced prompt engineering \n",
    "techniques using Business GPT to enhance data-sharing and collaboration \n",
    "across departments. Future steps involve integrating real-time data retrieval \n",
    "and refining models for more business-specific tasks.\n",
    "\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
